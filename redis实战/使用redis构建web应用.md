* 从高层次的角度来看，Web应用就是通过HTTP协议对网页浏览器发送的请求进行响应的服 务器或者服务(service )。一个Web服务器对请求进行响应的典型步骤如下。
  * 服务器对客户端发来的请求(request)进行解析
  * 请求被转发给一个预定义的处理器(handler)
  * 处理器可能会从数据库中取出数据
  * 处理器根据取出的数据对模板(template )进行渲染(render)
  * 处理器向客户端返回渲染后的内容作为对请求的响应(response )

* 以上列举的5个步骤从高层次的角度展示了典型Web服务器的运作方式,这种情况下的Web 请求被认为是无状态的(stateless),也就是说，服务器本身不会记录与过往请求有关的任何信息， 这使得失效(fail)的服务器可以很容易地被替换掉。

#### 登录和cookie缓存

* 每当我们登录互联网服务(比如银行账户或者电子邮件)的时候，这些服务都会使用 cookie 来记录我们的身份。cookie由少量数据组成，网站会要求我们的浏览器存储这些数据， 并在每次服务发送请求时将这些数据传回给服务。对于用来登录的cookie,有两种常见的方法可以将登录信息存储在cookie里面:一种是签名(signed)cookie,另一种是令牌(token )cookie 

* 签名cookie通常会存储用户名，可能还有用户ID、用户最后一次成功登录的时间，以及网站觉得有用的其他任何信息。除了用户的相关信息之外，签名cookie还包含一个签名，服务器可以使用这个签名来验证浏览器发送的信息是否未经改动(比如将cookie中的登录用户名改成另一个用户)

* 令牌cookie会在cookie里面存储一串随机字节作为令牌，服务器可以根据令牌在数据库中 查找令牌的拥有者。随着时间的推移，旧令牌会被新令牌取代。

* 签名cookie和令牌cookie的优点与缺点

  | cookie类型 | 优点                                                         | 缺点                                                         |
  | ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | 签名cookie | 验证cookie所需的一切信息都存储在cookie里面。 cookie可以包含额外的信息(additional infomation),并且对这些信息进行签名也很容易 | 正确地处理签名很难。很容易忘记对数据 进行签名，或者忘记验证数据的签名，从而造成安全漏洞 |
  | 令牌cookie | 添加信息非常容易。cookie的体积非常小，因此移动终 端和速度较慢的客户端可以更快地发送请求 | 需要在服务器中存储更多信息。如果使用 的是关系数据库，那么载入和存储cookie 的代价可能会很高 |

* 一般来说，用户在决定购买某个或某些商品之前，通常都会先浏览多个不同的商品，而记录 用户浏览过的所有商品以及用户最后一次访问页面的时间等信息，通常会导致大量的数据库写入。从长远来看，用户的这些浏览数据的确非常有用，但问题在于，即使经过优化，大多数关系数据库在每台数据库服务器上面每秒也只能插入、更新或者删除200〜2000个数据库行。尽管批 量插入、批量更新和批量删除等操作可以以更快的速度执行，但因为客户端每次浏览网页都只更 新少数几个行，所以高速的批量插入在这里并不适用。

* 首先，我们将使用一个散列来存储登录cookie令牌与已登录用户之间的映射。要检查一个用 户是否已经登录，需要根据给定的令牌来查找与之对应的用户，并在用户已经登录的情况下，返 回该用户的ID。

  ```
  def checkToken(conn, token)
  	return conn.hget('login', token);
  ```

* 对令牌进行检查并不困难，因为大部分复杂的工作都是在更新令牌时完成的:用户每次 浏览页面的时候，程序都会对用户存储在登录散列里面的信息进行更新，并将用户的令牌和 当前时间戳添加到记录最近登录用户的有序集合里面；如果用户正在浏览的是一个商品页面， 那么程序还会将这个商品添加到记录这个用户最近浏览过的商品的有序集合里面，并在被记 录商品的数量超过25个时，对这个有序集合进行修剪。

  ```
  def updateToken(conn, token, user, item=None): 
  	timestamp = time.time ()	//获取当前时间戳。
  	conn.hset('login', token, user) // 维持令牌和用户之间的关系
  	conn.zadd('recent', token, timestamp) //记录令牌最后的出现时间
  	if item:
  		rconn.zadd('viewed:' + token, item, timestamp)
  		conn.zremrangebyrank('viewed:' + token, 0, -26)
  ```

  通过update_token ()函数，我们可以记录用户最后一次浏览商品的时间以及用户最近浏 览了哪些商品。在一台最近几年生产的服务器上面，使用update_token()函数每秒至少可以 记录20 000件商品

* 因为存储会话数据所需的内存会随着时间的推移而不断增加，所以我们需要定期清理旧 的会话数据。为了限制会话数据的数量，我们决定只保存最新的1000万个会话。

  * 清理旧会 话的程序由一个循环构成，这个循环每次执行的时候，都会检查存储最近登录令牌的有序集 合的大小，如果有序集合的大小超过了限制，那么程序就会从有序集合里面移除最多100个 最旧的令牌，并从记录用户登录信息的散列里面，移除被删除令牌对应的用户的信息，并对 存储了这些用户最近浏览商品记录的有序集合进行清理。与此相反，如果令牌的数量未超过 限制，那么程序会先休眠1秒，之后再重新进行检查。

* Redis的过期数据处理 随着对Redis的了解逐渐加深，读者应该会慢慢发现本书展示的一些解决方案有时候并不是问题的唯一解决办法。比如对于这个登录cookie例子来说，我们可以直接将登录 用户和令牌的信息存储到字符串键值对里面，然后使用Redis的EXPIRE命令，为这个字符串和记 录用户商品浏览记录的有序集合设置过期时间，让Redis在一段时间之后自动删除它们，这样就不 需要再使用有序集合来记录最近出现的令牌了。但是这样一来，我们就没有办法将会话的数量限制 在1000万之内了，并且在将来有需要的时候，我们也没办法在会话过期之后对被废弃的购物车进 行分析了。

* 熟悉多线程编程或者并发编程的读者可能会发现代码清单2.3展示的清理函数实际上包含一 个竞争条件(race condition ):如果清理函数正在删除某个用户的信息，而这个用户又在同一时 间访问网站的话，那么竞争条件就会导致用户的信息被错误地删除。目前来看，这个竞争条件除 了会使得用户需要重新登录一次之外，并不会对程序记录的数据产生明显的影响。

* 通过使用Redis来记录用户信息，我们成功地将每天要对数据库执行的行写入操作减少了数 百万次。虽然这非常的了不起，但这只是我们使用Redis构建Web应用程序的第一步，接下来的 一节将向读者们展示如何使用Redis来处理另一种类型的cookie

#### 使用Redis实现购物车

* 网景(Netscape )公司在20世纪90年代中期最先在网络中使用了 cookie,这些cookie最终 变成了我们在上一节讨论的登录会话cookieo cookie最初的意图在于为网络零售商(web retailer ) 提供一种购物车，让用户可以收集他们想要购买的商品。在cookie之前，有过几种不同的购物车 解决方案，但这些方案全都不太好用。

* 使用cookie实现购物车—— 就是将整个购物车都存储到cookie里面的做法非常常见，这 种做法的一大优点是无须对数据库进行写入就可以实现购物车功能，而缺点则是程序需要重新解 析和验证(validate) cookie,确保cookie的格式正确，并且包含的商品都是真正可购买的商品。 cookie购物车还有一个缺点:因为浏览器每次发送请求都会连cookie一起发送，所以如果购物车 cookie的体积比较大，那么请求发送和处理的速度可能会有所降低。

* 因为我们在前面已经使用Redis实现了会话cookie和记录用户最近浏览过的商品这两个特 性，所以我们决定将购物车的信息也存储到Redis里面,并且使用与用户会话cookie相同的cookie ID来引用购物车。

* 购物车的定义非常简单:每个用户的购物车都是一个散列，这个散列存储了商品ID与商品订购 数量之间的映射。对商品数量进行验证的工作由Web应用程序负责，我们要做的则是在商品的订购 数量出现变化时，对购物车进行更新:如果用户订购某件商品的数量大于0,那么程序会将这件商品 的ID以及用户订购该商品的数量添加到散列里面，如果用户购买的商品已经存在于散列里面，那么 新的订购数量会覆盖已有的订购数量；相反地，如果用户订购某件商品的数量不大于0,那么程序将 从散列里面移除该条目。

  ```
  def add_to_cart(conn, session, item, count) 
      if count <= 0:
          conn.hrem('cart:' + session, item)
      else:
          conn.hset('cart:' + session, item, count)
  ```

  接着，我们需要对之前的会话清理函数进行更新，让它在清理旧会话的同时，将旧会话对应 用户的购物车也一并删除

* 我们现在将会话和购物车都存储到了 Redis里面，这种做法除了可以减少请求的体积之外， 还使得我们可以根据用户浏览过的商品、用户放入购物车的商品以及用户最终购买的商品进行统 计计算，并构建起很多大型网络零售商都在提供的“在查看过这件商品的用户当中，有A%的用 户最终购买了这件商品”“购买了这件商品的用户也购买了某某其他商品”等功能，这些功能可 以帮助用户查找其他相关的商品，并最终提升网站的销售业绩。

* 通过将会话cookie和购物车cookie存储在Redis里面，我们得到了进行数据分析所需的两个 重要的数据来源，接下来的一节将展示如何使用缓存来减少数据库和Web前端的负载。

#### 网页缓存

* 在动态生成网页的时候，通常会使用模板语言(templating language )来简化网页的生成操作。 需要手写每个页面的日子已经一去不复返一现在的Web页面通常由包含首部、尾部、侧栏菜 单、工具条、内容域的模板生成，有时候模板还用于生成JavaScript

* 通过对浏览数据进行分析，Fake Web Retailer发现自己所处理的95%的Web页面每天最多只 会改变一次，这些页面的内容实际上并不需要动态地生成，而我们的工作就是想办法不再生成这 些页面。减少网站在动态生成内容上面所花的时间，可以降低网站处理相同负载所需的服务器数 量，并让网站的速度变得更快。(研究表明，减少用户等待页面载入的时间，可以增加用户使用 网站的欲望，并改善用户对网站的印象。)

* 所有标准的应用框架都提供了在处理请求之前或者之后添加层(layer)的能力，这 些层通常被称为中间件(middleware )或者插件(plugin )。我们将创建一个这样的层来调用Redis 缓存函数:对于一个不能被缓存的请求，函数将直接生成并返回页面；而对于可以被缓存的请求， 函数首先会尝试从缓存里面取出并返回被缓存的页面，如果缓存页面不存在，那么函数会生成页 面并将其缓存在Redis里面5分钟，最后再将页面返回给函数调用者。

  ```
  def cache_request(conn, request, callback): 
      if not can_cache(conn, request): 
      	return calIback(request)
      page_key = 'cache:' + hash_request(request) 
      	content = conn.get(page_key)
      if not content:
      	content = callback(request) 
      	conn.setex(page_key, content, 300)
      return content
  ```

  缓存函数可以让网站在5分钟之内无需再为它们动态地生成视图页面。取决于网页的内容 有多复杂，这一改动可以将包含大量数据的页面的延迟值从20〜50毫秒降低至查询一次Redis 所需的时间:查询本地Redis的延迟值通常低于1毫秒，而查询位于同一个数据中心的Redis的 延迟值通常低于5毫秒。对于那些需要访问数据库的页面来说，这个缓存函数对于减少页面载入 时间和降低数据库负载的作用会更加显著。

#### 数据行缓存

* 到目前为止，我们已经将原本由关系数据库和网页浏览器实现的登录和访客会话转移到了 Redis上面实现；将原本由关系数据库实现的购物车也放到了 Redis ±面实现；还将所有页面缓存 到了 Redis里面。这一系列工作提升了网站的性能，降低了关系数据库的负载并减少了网站成本。

* Fake Web Retailer的商品页面通常只会从数据库里面载入一两行数据，包括已登录用户的用 户信息(这些信息可以通过AJAX动态地载入，所以不会对页面缓存造成影响)和商品本身的信 息。即使是那些无法被整个缓存起来的页面一一比如用户账号页面、记录用户以往购买商品的页 面等等，程序也可以通过缓存页面载入时所需的数据库行来减少载入页面所需的时间。

* 为了展示数据行缓存的作用，我们假设Fake Web Retailer为了清空旧库存和吸引客户消费， 决定开始新一轮的促销活动:这个活动每天都会推出一些特价商品供用户抢购，所有特价商品的 数量都是限定的，卖完即止。在这种情况下，网站是不能对整个促销页面进行缓存的，因为这可 能会导致用户看到错误的特价商品剩余数量，但是每次载入页面都从数据库里面取岀特价商品的剩余数量的话，又会给数据库带来巨大的压力，并导致我 们需要花费额外的成本来扩展数据库。

* 为了应对促销活动带来的大量负载，我们需要对数据 行进行缓存，具体的做法是:编写一个持续运行的守护进 程函数，让这个函数将指定的数据行缓存到Redis里面， 并不定期地对这些缓存进行更新。缓存函数会将数据行编 码(encode )为JSON字典并存储在Redis的字符串里面， 其中，数据列(column )的名字会被映射为JSON字典的 键，而数据行的值则会被映射为JSON字典的值

* 程序使用了两个有序集合来记录应该在何时对缓存进行更新:

  * 第一个有序集合为调度 (schedule )有序集合，它的成员为数据行的行ID,而分值则是一个时间戳，这个时间戳记 录了应该在何时将指定的数据行缓存到Redis里面；
  * 第二个有序集合为延时(delay)有序集合，它的成员也是数据行的行ID,而分值则记录了指定数据行的缓存需要每隔多少秒更新一次

* 为了让缓存函数定期地缓存数据行，程序首先需要将行ID和给定的延迟值添加到延迟有序 集合里面，然后再将行ID和当前时间的时间戳添加到调度有序集合里面。实际执行缓存操作的 函数需要用到数据行的延迟值，如果某个数据行的延迟值不存在，那么程序将取消对这个数据 行的调度。如果我们想要移除某个数据行已有的缓存，并且让缓存函数不再缓存那个数据行，那么只需要把那个数据行的延迟值设置为小于或等于0就可以了。

  ```
  def schedule_row_cache(connr row_id, delay):
  	conn.zadd('delay:', row_id, delay) 
  	conn.zadd('schedule:', row_id, time.time())
  ```

* 现在我们已经完成了调度部分，那么接下来该如何对数据行进行缓存呢？负责缓存数据行的 函数会尝试读取调度有序集合的第一个元素以及该元素的分值，如果调度有序集合没有包含任何 元素，或者分值存储的时间戳所指定的时间尚未来临，那么函数会先休眠50毫秒，然后再重新 进行检查。当缓存函数发现一个需要立即进行更新的数据行时，缓存函数会检查这个数据行的延 迟值:如果数据行的延退值小于或者等于0,那么缓存函数会从延迟有序集合和调度有序集合里 面移除这个数据行的ID.并从缓存里面删除这个数据行已有的缓存，然后再重新进行检查；对于 延迟值大于0的数据行来说，缓存函数会从数据库里面取出这些行，将它们编码为JSON格式并存 储到Redis里面，然后更新这些行的调度时间。

  ```
  def cache_rows(conn): 
  while not QUIT:
  	next = conn.zrange('schedule:', 0, 0, withscores = true)
  	now = time.time()
  	if not next or next[0][1] > now:
  		time.sleep(.05) 
  		continue
      row_id = next[0][0]
      delay = conn.zscore(1 delay:', row_id) 
      if delay <= 0:
          conn.zrem('delay:', row_id)
          conn.zrem('schedule:', row_id) 
          conn.delete ('inv:' + row_id) 
          continue
      row = Inventory.get(row_id)
  	conn.zadd('schedule:', row_id, now + delay) 
  	conn.set('1inv:', + row_id, json.dumps(row.to_dict()))
  ```

  通过组合使用调度函数和持续运行缓存函数,我们实现了一种重复进行调度的自动缓存机制, 并且可以随心所欲地控制数据行缓存的更新频率:如果数据行记录的是特价促销商品的剩余数量, 并且参与促销活动的用户非常多的话，那么我们最好每隔几秒更新一次数据行缓存；另一方面，如果数据并不经常改变，或者商品缺货是可以接受的，那么我们可以每分钟更新一次缓存。

#### 网页分析

* 网站可以从用户的访问、交互和购买行为中收集到有价值的信息。例如，如果我们只想关注那些浏览量最高的页面，那么我们可以尝试修改页面的格局、配色甚至是页面上展示的其他链接。 每一个修改尝试都能改变用户对一个页面或者后续页面的体验，或好或坏，甚至还能影响用户的购买行为。

* 对于大数据的商城而言，冒然地缓存所有商品页面将耗尽整个网站的全部内存！经过一番调研之后，我们决定 只对其中10 000件商品的页面进行缓存。

* 每个用户都有一个相应的记录用户浏览商品历史的有序集合，尽管使用这些有序集合可以计算出用户最经常浏览的商品，但进行这种计算却需要耗费大量的时间。

* 修改后的update__token()函数

  ```
  def update_token(conn, token, user, item=None): 
      timestamp = time.time()
      conn.hset('login:', token, user)
      conn.zadd('recent:', token, timestamp)
      if item:
          conn.zadd('viewed:' + token, item, timestamp)
          conn.zremrangebyrank('viewed:' + token, 0, -26)
          conn.zincrby('viewed:', item, -1)
  ```

  新添加的代码记录了所有商品的浏览次数，并根据浏览次数对商品进行了排序，被浏览得最 多的商品将被放到有序集合的索引。位置上，并且具有整个有序集合最少的分值。随着时间的流 逝，商品的浏览次数会呈现两极分化的状态，一些商品的浏览次数会越来越多，而另一些商品的 浏览次数则会越来越少,除了缓存最常被浏览的商品之外，程序还需要发现那些变得越来越流行 的新商品，并在合适的时候缓存它们。

* 为了让商品浏览次数排行榜能够保持最新，我们需要定期修剪有序集合的长度并调整已有元素的分值，从而使得新流行的商品也可以在排行榜里面占据一席之地。而调整元素分值的动作则可以通过ZINTERSTORE命令来完成。ZINTERSTORE命令可以组合起一个或多个有序集合，并将有序集合包含的每个分值都乘以一个给定的数值(用户可以为每个有序集合分别指定不同的相乘数值)。每隔5分钟，就会删除所有排名在20000名之后的商品，并将删除之后剩余的所有商品的浏览次数减半。

  ```
  def rescale_viewed(conn):
      while not QUIT:
          conn.zremrangebyrank('viewed:', 0, -20001)
          conn.zinterstore('viewed:', ('viewed:': .5))
          time.sleep(300)
  ```

* 通过记录商品的浏览次数，并定期对记录浏览次数的有序集合进行修剪和分值调整，我们建立起了一个持续更新的最常浏览商品排行榜。接下来要做的就是修改之前介 绍过的can_cache()函数，让它使用新的方法来判断页面是否需要被缓存

  ```
  def can_cache (conn, request):	
      item_id = extract_item_id(request)
      if not item_id or is_dynamic(request): 
      	return False
      rank = conn.zrank('viewed:', item_id)
      return rank is not None and rank < 10000 // 取得商品的浏览次数排名。根据商品的浏览次数排名来判断是否需要缓存这个页面。
  ```

* 通过使用前面介绍的几个函数，Fake Web Retailer现在可以统计商品被浏览的次数，并以此 来缓存用户最经常浏览的10 000个商品页面。如果我们想以最少的代价来存储更多页面，那么 可以考虑先对页面进行压缩，然后再缓存到Redis里面；或者使用Edge Side Includes技术移除页 面中的部分内容；又或者对模板进行提前优化(pre-optimize),移除所有非必要的空格字符。这 些技术能够减少内存消耗并增加Redis能够缓存的页面数量，为访问量不断增长的网站带来额外 的性能提升。



