#### 自动补全

* 在Web领域里面，自动补全(autocomplete )是一种能够让用户在不进行搜索的情况下，快速找到所需东西的技术。自动补全一般会根据用户已输入的字母来查找所有以已输入字母为开头 的单词，有些自动补全甚至可以在用户输入句子开头的时候自动补充完整个句子。比如说，Web浏览器在用户向地址栏中输入信息的时候，也会通过自动补全来展示用户最近访问过的网址，以此来帮助用户快速地再次访问某个网站，另外Web浏览器内置的自动补全还会帮助用户记忆各个网站的登录名。以上提到的各种自动补全功能都旨在帮助用户更快地访问信息。类似Google搜索栏这样的自动补全是由很多 TB的远程数据驱动的，而类似浏览器历史记录和网站登录框这样的自动补全则是由体积小得多的本地数据库驱动的。但所有的这些自动补全功能都可以让我们在更短的时间内找到想要的东西。

##### 自动补全最近联系人

* 将实现一个用于记录最近联系人的自动补全程序。为了让用户快速地查找和记忆亲密的玩家，Fake Game公司正考虑为他们的客户端创建一个联系人列表，并使用这个列表来记录每个用户最近联系过的100个玩家。 当用户打算在客户端发起一次聊天并开始输入聊天对象的名字时，自动补全就会根据用户已经输入的文字，列 出那些昵称以已输入文字为开头的人。

* 因为服务器上的数百万用户都需要有一个属于自己的 联系人列表来存储最近联系过的100个人，所以我们需要在 能够快速向列表里面添加用户或者删除用户的前提下，尽量 减少存储这些联系人列表带来的内存消耗。因为Redis的列表会以有序的方式来存储元素，并且 和Redis提供的其他结构相比，列表占用的内存是最少的，所以我们选择使用列表来存储用户的联系 人信息。可惜的是，Redis列表提供的功能并不足以让我们在Redis内部完成自动补全操作，因此实际的自动补全操作将会放到Redis之外的Python里面执行，这种做法使得程序可以尽量减少Redis存储 和更新用户最近联系人列表所需的内存数量，并将较为简单的过滤工作交给Python来执行。

* 构建最近联系人自动补全列表通常需要对Redis执行3个操作。第一个操作就是添加或者更 新一个联系人，让他成为最新的被联系用户，这个操作包含以下3个步骤。

  * 如果指定的联系人已经存在于最近联系人列表里面，那么从列表里面移除他。
  * 将指定的联系人添加到最近联系人列表的最前面。
  * 如果在添加操作完成之后，最近联系人列表包含的联系人数量超过了 100个，那么对列表进行修剪，只保留位于列表前面的100个联系人。

* 以上描述的3个操作可以通过依次执行LREM命令、LPUSH命令和LTR1M命令来实现，并且为了确保操作不会带有任何竞争条件，我们会使用由MULTI命令 和EXEC命令构成的事务包裹起LREM、LPUSH和LTRIM这3个命令。

  ```python
  def add_update_contact(conn, user, contact):
    ac_list = 'recent:' + user
    pipeline = conn.pipe1ine(True)
    pipeline.lrem(ac_list, contact) 
    pipeline.lpush(ac_list, contact)
    pipeline.Itrim(ac_list, 0, 99) 
    pipeline.execute()
  ```

  跟之前提到过的一样，如果指定的联系人已经存在，那么add_update_contact ()函数 将从列表里面移除该联系人，然后将他重新推入列表的最左端，最后对列表进行修剪以防止联系 人人数超过限制。

* 构建最近联系人自动补全列表要做的第二个操作，就是在用户不想再看见某个联系人的时候，将指定的联系人从联系人列表里面移除掉，这个操作可以通过以下这个LREM调用来完成:

  ```
  def remove_contact(conn, user, contact): 
  	conn.lrem('recent:' + user, contact)
  ```

* 构建最近联系人自动补全列表需要执行的最后一个操作，就是获取自动补全列表并査找匹配的用户。因为实际的自动补全处理是在Python里面完成的，所以操作需要首先获取整个列表结构，然后再在Python里面处理它

  ```python
  def fetch_autocomplete_list(conn, user, prefix): 
    candidates = conn.1range('recent:' + user, 0, -1)
    matches =[]	
    for candidate in candidates:
      if candidate.lower().startswith(prefix):
        matches.append(candidate)
    return matches
  ```

* 因为我们已经预先考虑到了 “从列表里面移除一个元素所需的时间与列表长度成正比” 这个问题，并明确地限制最近联系人列表最多只能存储100个联系人，所以本节给岀的自动 补全实现可以运行得非常好，并且速度也足够快，但它并不适合用来处理非常大的列表。如果你需要一个能够存储更多元素的最常使用列表(most-recently-used list)或者最少使用列表 (least-recently-used list),那么可以考虑使用带有时间戳的有序集合来代替本节介绍的最近联系人列表。

##### 通讯录自动补全

* 在前面的自动补全例子里面，Redis主要用于记录联系人列表，而非实际地执行自动补全操作。 对于比较短的列表来说，这种做法还算可行，但对于非常长的列表来说，仅仅为了找到几个元素而获取成千上万个元素，是一种非常浪费资源的做法。因此，为了对包含非常多元素的列表进行自动补全，我们必须直接在Redis内部完成查找匹配元素的工作。

* 带有自动补全特性的最近联系人聊天功能是游戏里面最常用的社交功能，而游戏中第二常用的社交功能——邮件功能正在变得越来越受欢迎，为了让邮件功能的发展势头继续保持下去，我们将为邮件功能添加自动补全特性。但是为了防止邮件功能被滥用， 并避免用户接收到不请自来的邮件，我们决定只允许用户向属于同一 “公会”(公会就是游戏里面的社交群组)的其他玩家发送邮件。因为一个公会可能会有好几千个成员，所以我们没办法在这里使用之前介绍的基于列表实现 的自动补全程序，但是由于每个公会只需要一个自动补全列表，所以在实现这个列表的时候可以稍微多花费一些内存。为了在客户端进行自动补全的时候，尽量减少服务器需要传输给客户端的数据量，我们将使用有序集合来直接在Redis内部完成自动补全的前缀计算工作。

* 为了存储公会自动补全列表，我们将以一种之前未曾介绍过的方式来使用有序集合。在大多数情况下，我们使用有序集合是为了快速地判断某个元素是否存在于有序集合里面、査看某个成员在有序集合中的位置或索引，以及从有序集合的某个地方快速地按范围取出多个元素。然而这 一次，我们将把有序集合里面的所有分值都设置为0——这种做法使得我们可以使用有序集合的另一个特性:当所有成员的分值都相同时，有序集合将根据成员的名字来进行排序；而当所有成员的分值都是0的时候，成员将按照字符串的二进制顺序进行排序。为了执行自动补全操作，程序会以小写字母的方式插入联系人的名字，并且为了方便起见，程序规定用户的名字只能包含英文字母，这样的话就不需要考虑如何处理数字或者符号了。

* 那么我们该如何实现这个自动补全功能呢？首先，如果我们将用户的名字看作是类似abc,abca, abed,…，abd这样的有序字符串序列，那么查找带有abc前缀的单词实际上就是查找介于abbz・・・之后和abd之前的字符串。如果我们知道第一个排在abbz之前的元素的排名以 及第一个排在abd之后的元素的排名，那么就可以用一个ZRANGE调用来取得所有介于abbz ... 和abd之间的元素，而问题就在于我们并不知道那两个元素的具体排名。为了解决这个问题， 我们需要向有序集合分别插入两个元素，一个元素排在abbz...的后面，而另一个元素则 排在abd的前面，接着根据这两个元素的排名来调用ZRANGE命令，最后移除被插入的两个 元素。

* 因为在ASC1I编码里面，排在z后面的第一个字符就是左花括号｛,所以我们只要将｛拼接到 abc前缀的末尾，就可以得出元素abc｛,这个元素既位于abc之前，又位于所有带有abc前 缀的合法名字之后。同样的，只要将｛追加到abb的末尾，就可以得出元素abb｛,这个元素位 于所有带有abc前缀的合法名字之前，可以在按范围查找所有带有abc前缀的名字时，将其用 作起始元素。另一方面，因为在ASCII编码里面，第一个排在a前面的字符就是反引号、，所以 如果我们要査找的是带有aba前缀的名字，而不是带有abc前缀的名字，那么可以使用ab'作 为范围查找的起始元素，并将aba ｛用作范围查找的结束元素。

* 综上所述，通过将给定前缀的最后一个字符替换为第一个排在该字符前面的字符，可以得到 前缀的前驱(predecessor ),而通过给前缀的末尾拼接上左花括号，可以得到前缀的后继 (successor )o为了防止多个前缀搜索同时进行时出现任何问题，程序还会给前缀拼接一个左花 括号，以便在有需要的时候，根据这个左花括号来过滤掉被插入有序集合里面的起始元素和结束 元素。代码清单6・3展示了这个根据给定前缀生成查找范围的函数。因为前面花了那么多篇幅来描述如何根据给定的前缀来生成查找范围，所以可能会有读者对 这个功能

  ```
  valid_characters = *'abedefghijklmnopqrstuvwxyz
  def find__prefix_range(prefix):
    posn = bisect.bisect_left(valid_characters, suffix = valid_characters[(posn or 1) - 1]
    return prefix[:-1] + suffix + '{' , prefix + '{'
  ```

* 字符集与国际化 

  * 对于只使用a〜z字符的语言来说，这个在ASCII编码里面查找前一个字符和后 一个字符的方法可以运作得非常好，但如果你要处理的字符并不仅仅限于a〜z范围，那么你还需 要解决其他几个问题。
  * 首先，你需要想办法把所有字符都转换为字节，常见的做法是使用UTF-8、UTF-16或者UTF-32
    字符编码(UTF-16和UTF-32有大端版本和小端版本可用，但只有大端版本可以在我们所处的情况下运作)。其次，你需要找出自己想要支持的字符范围，并确保你的字符编码在你所选范围的前面和后面都至少留有一个字符。最后，你需要使用位于范围前面和后面的字符来分别代替前面例子中的反引号'和左花括号｛。
  * 好在我们的算法只关心编码而不是字符在底层的排列顺序，所以无论你使用的是UTF-8,还 是大端或者小端的UTF・16、UTF-32,你都可以使用空字节(null)来代替反引号，并使用你的编码 和语言支持的最大值来代替左花括号。(某些语言的绑定数量是比较有限的，它们在UTF.16上面最 大只能支持Unicode码点U+2ffff，在UTF-32上面最大只能支持Unicode码点U+2ffff )

* 在确认了需要查找的范围之后，程序会将起始元素和结束元素插入有序集合里面，然后查看两个被插入元素的排名，并从它们之间取出一些元素，最后再从有序集合里面移除这两个元素(为了避免滋扰用户，程序最多只会取出10个元素)。为了防止自动补全程序在多个公会成员同时向同一个公会成员发送消息的时候，将多个相同的起始元素和结束元素重复地添加到有序集合里 面，或者错误地从有序集合里面移除了由其他自动补全程序添加的起始元素和结束元素，自动补 全程序会将一个随机生成的128位全局唯一标识符(UUID )添加到起始元素和结束元素的后面。 另外自动补全程序还会在插入起始元素和结束元素之后，通过使用WATCH、MULTI和EXEC来 确保有序集合不会在进行范围查找和范围取值期间发生变化。

  ```python
  def autocomplete_on_prefix(conn, guild, prefix): 
    start, end = find_prefix_range(prefix) 
    identifier = str(uuid.uuid4()) 
    start +=identifier 
    end += identifier
    zset_name = 'members:' + guild
    conn.zadd(zset_name, start, end)
    pipeline = conn.pipeline(True)
    while 1:
      try:
        pipeline.watch(zset_name) 
        sindex = pipeline.zrank(zset_name, start)
        eindex = pipeline.zrank(zset_name, end)
        erange = min(sindex + 9, eindex - pipeline.multi()
        pipeline.zrem(zset_name, start, end)
        pipeline.zrange(zset_name, sindex, erange) 
        items = pipeline.execute()[-1] 
        break
      except redis.exceptions.WatchError:
        continue
      return [item for item in items if '{' not in item]
  ```

  autocomplete_on_prefix() 函数的大部分代码都用于簿记和设置工作。函数首先获取 起始元素和结束元素，并将它们添加到公会的自动补全有序集合里面，在添加操作完成之后，函 数会使用WATCH命令来监视有序集合，并根据起始元素和结束元素在有序集合中的排名，从它们 之间取出一些元素，最后执行相应的清理操作。

* 加入公会和离开公会这两个操作的实现都非常简单直接:前者只需要使用ZADD命令将用户 添加到公会的有序集合里面就可以了，而后者只需要使用ZREM命令将用户从公会的有序集合里 面移除掉就可以了。

  ```python
  def join_guiId(conn, guild, user):
    conn.zadd('members:' + guild, user, 0)
  def leave_guild(conn, guild, user):
    conn.zrem('members:' + guild, user)
  ```

  对于自动补全来说，加入公会或者离开公会都是非常简单的——只要将用户的名字加入有序 集合里面，或者从有序集合里面移除用户的名字就可以了。

* 通过向有序集合添加元素来创建查找范围，并在取得范围内的元素之后移除之前添加的元 素，这是一种非常有用的技术。虽然本章只将这种技术用在了实现自动补全上面，但是这种技术同样可以应用在任何已排序索引(sorted index )上面。
* 在自动补全程序向有序集合里面添加起始元素和结束元素的时候，我们需要谨慎地处理其他正在执行的自动补全操作，这也是程序里面用到了 WATCH命令的原因。但是随着负载的增加， 程序进行重试的次数可能会越来越多，导致资源被白白浪费。接下来的一节将介绍如何通过使用锁来减少对WATCH命令的使用，甚至使用锁来代替WATCH命令，从而达到避免重试、提升性能并在某些情况下简化代码的效果。

#### 分布式锁

* 一般来说，在对数据进行“加锁”时，程序首先需要通过获取(acquire )锁来得到对数据进行排他性访问的能力，然后才能对数据执行一系列操作，最后还要将锁释放(release )给其他程序。对于能够被多个线程访问的共享内存数据结构(shared-memory data structure )来说，这种“先获取锁，然后执行操作，最后释放锁”的动作非常常见。Redis使用 WATCH 命令来代替对数据进行加锁，因为WATCH只会在数据被其他客户端抢先修改了的情况下通知执行了这个命令的客户 端，而不会阻止其他客户端对数据进行修改，所以这个命令被称为乐观锁(optimistic locking )
* 分布式锁也有类似的“首先获取锁，然后执行操作，最后释放锁”动作，但这种锁既不是给同一个进程中的多个线程使用，也不是给同一台机器上的多个进程使用，而是由不同机器上的不同Redis客户端进行获取和释放的。何时使用以及是否使用WATCH或者锁取决于给定的应用程序:有的应用不需要使用锁就可以正确地运行，而有的应用只需要使用少量的锁，还有的应用需要在每个步骤都使用锁，不一而足。
* 我们没有直接使用操作系统级别的锁、编程语言级别的锁，或者其他各式各样的锁，而是选择了花费大量时间去使用Redis构建锁，这其中一个原因和范围(score )有关:为了对 Redis存储的数据进行排他性访问，客户端需要访问一个锁，这个锁必须定义在一个可以让所有客户端都看得见的范围之内，而这个范围就是Redis本身，因此我们需要把锁构建在Redis 里面。另一方面，虽然Redis提供的SETEX命令确实具有基本的加锁功能，但它的功能并不完整，并且也不具备分布式锁常见的一些高级特性，所以我们还是需要自己动手来构建分布 式锁。
* 这一节将会说明“为什么使用WATCH命令来监视被频繁访问的键可能会引起性能问题”，还会展示构建一个锁的详细步骤，并最终在某些情况下使用锁去代替WATCH命令。
* 为什么WATCH、MULTI和EXEC组成的事务并不具有可 扩展性，原因在于程序在尝试完成一个事务的时候，可能会因为事务执行失败而反复地进行重试。 保证数据的正确性是一件非常重要的事情，但使用WATCH命令的做法并不完美。

##### 简易锁

* 因为客户端即使在使用锁的过程中也可能会因为这样或那样的原因而下线，所以为了防止客户端在取得锁之后崩溃，并导致锁一直处于“已被获取”的状态，最终版的锁实现将带有超时限制特性:如果获得锁的进程未能在指定的时限内完成操作，那么锁将自动被释放。
* 虽然很多Redis用户都对锁(lock)、加锁(locking)及锁超时(lock timeouts )有所了解, 但遗憾的是，大部分使用Redis实现的锁只是基本上正确，它们发生故障的时间和方式通常难以预料。下面列出了一些导致锁岀现不正确行为的原因，以及锁在不正确运行时的症状。
  * 持有锁的进程因为操作时间过长而导致锁被自动释放，但进程本身并不知晓这一点，甚至还可能会错误地释放掉了其他进程持有的锁。
  * 一个持有锁并打算执行长时间操作的进程已经崩溃，但其他想要获取锁的进程不知道哪个进程持有着锁，也无法检测出持有锁的进程已经崩溃，只能白白地浪费时间等待锁被释放。
  * 在一个进程持有的锁过期之后，其他多个进程同时尝试去获取锁，并且都获得了锁。
  * 上面提到的第一种情况和第三种情况同时岀现，导致有多个进程获得了锁，而每个进程都以为自己是唯一一个获得锁的进程。
* 因为Redis在最新的硬件上可以每秒执行100 000个操作，而在高端的硬件上甚至可以每 秒执行将近225 000个操作，所以尽管上面提到的问题出现的几率只有万分之一，但这些问题在高负载的情况下还是有可能会出现。因此，让锁正确地运作起来仍然是一件相当重要的事情。

##### 使用Redis构建锁

* 使用Redis构建一个基本上正确的锁非常简单，如果在实现锁时能够对用到的操作多加留心的话，那么使用Redis构建一个完全正确的锁也并不是一件非常困难的事情。本节接下来要介绍的是锁实现的第1个版本，这个版本的锁要做的事就是正确地实现基本的加锁功能，而之后的一节将会介绍如何处理过期的锁以及因为持有者崩溃而无法释放的锁。

* 为了对数据进行排他性访问，程序首先要做的就是获取锁。SETNX命令天生就适合用来实现锁的获取功能，这个命令只会在键不存在的情况下为键设置值，而锁要做的就是将一个随机生成的128位UUID设置为键的值，并使用这个值来防止锁被其他进程取得。

* 如果程序在尝试获取锁的时候失败，那么它将不断地进行重试，直到成功地取得锁或者超过给定的时限为止。

  ```python
  def acquire_lock(conn, lockname, acquire_timeout=10):
    identifier = str (uuid.uuid4())	
    end = time.time() + acquire_timeout 
    while time.time() < end:
      if conn.setnx('lock:' + lockname, identifier): 
      	return identifier
      time.sleep(.001)
    return False
  ```

  acquire_lock() 函数的行为和前面描述的一样:它会使用SETNX命令，尝试在代表锁的键不存在的情况下，为键设置一个值，以此来获取锁；在获取锁失败的时候，函数会在给定的时限内进行重试，直到成功获取锁或者超过给定的时限为止(默认的重试时限为 10 秒)。

* 在实现了锁之后，我们就可以使用锁来代替针对市场的WATCH操作了。代码清单6-9展示了使用锁重新实现的商品购买操作:程序首先对市场进行加锁，接着检查商品的价格，并在确保买家有足够的钱来购买商品之后，对钱和商品进行相应的转移。当操作执行完毕之后，程序就会释放锁。

  ```python
  def purchase_item_with_lock(conn, buyerid, itemid, selllerid):
    buyer = "users:%s"%buyerid
    seller = "users:%s"%sellerid
    item = "%s.%s"%(itemid, sellerid) 
    inventory = "inventory:%s"%buyerid
    locked = acquire_lock(conn, market)
      return False
    pipe = conn.pipe1ine(True)
    try:
      pipe.zscore("market:", item)
      pipe.hget(buyer, 'funds')
      price, funds = pipe.execute() 
      if price is None or price > funds: 
        return None
     	pipe.hincrby(seller, funds, price)
     	pipe.hincrby(buyer, funds, -price)
     	pipe.sadd(inventory, itemid)
     	pipe.zrem("market:", item)
     	pipe.execute()
   	finally:
  		release_lock(conn, market, locked)
  ```

  release_lock()函数展示了锁释放操作的实现代码:函数首先使用WATCH命令监视代表锁的键，接着检查键目前的值是否和加锁时设置的值相同，并在确认值没有变化之后删除该键(这个检查还可以防止程序错误地释放同一个锁多次)。

  ```python
  def release_lock(conn, lockname, identifier): 
  pipe = conn.pipeline(True) 
  lockname = 'lock:' + lockname
  while True:
    try:
      pipe.watch(lockname)
      if pipe.get(lockname) == identifier: pipe.multi():
        pipe.delete(lockname)
      pipe.execute()
      return True
      pipe.unwatch()
      break
    except redis.exceptions.WatchError:
      pass
      return False	
  ```

* 和之前展示的商品购买操作一样，release_lock() 函数也做了很多措施来确保锁没有被修改。需要注意的一点是，对于目前的锁实现来说，release_lock() 函数包含的无限循环只会在极少数情况下用到——函数之所以包含这个无限循环，主要是因为之后介绍的锁实现会支持超时限制特性，而如果用户不小心地混合使用了两个版本的锁，就可能会引起解锁事务失败， 并导致上锁时间被不必要地延长。尽管这种情况并不常见，但为了保证解锁操作在各种情况下都能够正确地执行，我们还是选择在一开始就把这个无限循环添加到release_lock()函数里面。

#####  细粒度锁

* 在前面介绍锁实现以及加锁操作的时候，我们考虑的是如何实现与WATCH命令粒度相同的锁——这种锁可以把整个市场都锁住。因为我们是自己动手来构建锁实现，并且我们关心的 不是整个市场，而是市场里面的某件商品是否存在，所以我们实际上可以将加锁的粒度变得更 细一些。通过只锁住被买卖的商品而不是整个市场，可以减少锁竞争出现的几率并提升程序的 性能。
* 锁可以有效地避免 WATCH 实现因为买入操作竞争过多而导致延迟剧增甚至无法执行的问题。
* dogpile效应指的是，执行事务所需的时间 越长，就会有越多待处理的事务互相重叠，这种重叠增加了执行单个事务所需的时间，并使得那 些带有时间限制的事务失败的几率大幅上升，最终导致所有事务执行失败的几率和进行重试的几 率都大幅地上升，这对于WATCH实现的商品买卖操作来说，影响尤为严重。
* 在一些情况下，判断应该锁住整个结构还是应该锁住结构中的一小部分是一件非常简单的事 情。比如在前面的商品买卖例子中，我们要监视的关键数据为市场中的一件商品，而一件商品只 是整个市场中的一小部分数据，所以只锁住一件商品的做法无疑是正确的。但是，在需要锁住的 一小部分数据有不止一份的时候，又或者需要锁住结构的多个部分的时候，判断应该对小部分数 据进行加锁还是应该直接锁住整个结构就会变得困难起来。除此之外，使用多个细粒度锁也有引 发死锁的危险，一不小心就会导致程序无法正常运行。

##### 带有超时限制特性的锁

* 前面提到过，目前的锁实现在持有者崩溃的时候不会自动被释放，这将导致锁一直处于已被获取的状态。为了解决这个问题，在这一节中，我们将为锁加上超时功能。

* 为了给锁加上超时限制特性，程序将在取得锁之后，调用EXPIRE命令来为锁设置过期时间， 使得Redis可以自动删除超时的锁。为了确保锁在客户端已经崩溃(客户端在执行介于SETNX 和EXPIRE之间的时候崩溃是最糟糕的)的情况下仍然能够自动被释放，客户端会在尝试获取锁 失败之后，检査锁的超时时间，并为未设置超时时间的锁设置超时时间。因此锁总会带有超时时 间，并最终因为超时而自动被释放，使得其他客户端可以继续尝试获取已被释放的锁。

* 需要注意的一点是，因为多个客户端在同一时间内设置的超时时间基本上都是相同的，所以 即使有多个客户端同时为同一个锁设置超时时间，锁的超时时间也不会产生太大变化。

  ```
  def acquire_lock_with_timeout(conn, lockname, acquire_timeout=10, lock_timeout=10):
  	identifier = str(uuid.uuid4())
    lockname = 'lock:* + lockname
    lock_timeout = int(math.ceil(lock_timeout)) 
    end = time.time() + acquire_timeout 
    while ime.time() < end:
      if conn.setnx(lockname, identifier): 
      	conn.expire(lockname, lock_timeout) 
      	return identifier
      elif not conn.ttl(lockname):
        conn.expire(lockname, lock_timeout)
        time.sleep(.001)
    return False
  ```

  新的acquire_lock_with_timeout ()函数给锁增加了超时限制特性，这一特性确保了 锁总会在有需要的时候被释放，而不会被某个客户端一直把持着。更棒的是，这个新的加锁函数 可以和之前写好的锁释放函数一起使用，我们不需要另外再写新的锁释放函数。

* 在使用有序集合构建通讯录自动补全特性的时候，为了能够根据范围来获取多个通 讯录信息，程序需要花费一些工夫来创建范围的起始元素和结束元素，并将它们添加到有序集合 里面。因为多个自动补全操作可能会同时进行，所以程序不仅需要使用WATCH命令来监视有序 集合，以便在有需要的时候进行重试；还需要在范围获取操作执行完毕之后，移除有序集合中带 有左花括号({)的元素。这些要求给自动补全特性的实现增加了额外的复杂度，而如果我们使 用锁来代替WATCH命令的话，实现自动补全特性的难度就会大大降低。
* 在其他数据库里面，加锁通常是一个自动执行的基本操作。而Redis的WATCH、MULTI和 EXEC,就像之前所说的那样，只是一个乐观锁——这种锁只会在数据被其他客户端抢先修改 了的情况下，通知加锁的客户端，让它撤销对数据的修改，而不会真正地把数据锁住。通过在 客户端上面实现一个真正的锁，程序可以为用户带来更好的性能、更熟悉的编程概念、更简单 易用的API,等等。但是与此同时，也请记住Redis并不会主动使用这个自制的锁，我们必须 自己使用这个锁来代替WATCH,或者同时使用锁和WATCH协同进行工作，从而保证数据的正 确与一致。
* 在成功地构建带有超时限制特性的锁之后，我们接下来将要了解一种名为计数信号量 (counting semaphore)的锁，这种锁并没有一般的锁那么常用，但是当我们需要让多个客户端同 时访问相同的信息时，计数信号量就是完成这项任务的最佳工具。

#### 计数信号量

* 计数信号量是一种锁，它可以让用户限制一项资源最多能够同时被多少个进程访问，通常用于限定能够同时使用的资源数量。你可以把我们在前一节创建的锁看作是只能被一个进程访问的信号量。
* 计数信号量和其他种类的锁一样，都需要被获取和释放。客户端首先需要获取信号量，然后执行操作，最后释放信号量。计数信号量和其他锁的区别在于，当客户端获取锁失败的时候，客 户端通常会选择进行等待；而当客户端获取计数信号量失败的时候，客户端通常会选择立即返回 失败结果。举个例子，假设我们最多只允许5个进程同时获取信号量，那么当有第6个进程尝试去获取信号量的时候，我们希望这个获取操作可以尽早地失败，并向客户端返回“本资源目前正 处于繁忙状态”之类的信息。

##### 构建基本的计数信号量

* 构建计数信号量时要考虑的事情和构建其他类型的锁时要考虑的事情大部分都是相同的，比如判断是哪个客户端取得了锁，如何处理客户端在获得锁之后崩溃的情况，以及如何处理锁超时的问题。实际上，如果我们不考虑信号量超时的问题，也不考虑信号量的持有者在未释放信号量 的情况下崩溃的问题，那么有好几种不同的方法可以非常方便地构建出一个信号量实现。遗憾的 是，从长远来看，这些简单方便的方法构建出来的信号量都不太实用，因此我们将通过持续改进 的方式来提供一个功能完整的计数信号量。

* 使用Redis来实现超时限制特性通常有两种方法可选。一种是像之前构建分布式锁那样，使 用EXPIRE 而另一种则是使用有序集合。为了将多个信号量持有者的信息都存储到同一个 结构里面，这次我们将使用有序集合来构建计数信号量

* 说得更具体一点，程序将为每个尝试获取信号量的进程生成一个唯一标识符，并将这个标识 符用作有序集合的成员，而成员对应的分值则是进程尝试获取信号量时的Unix时间戳。

* 进程在尝试获取信号量时会生成一个标识符，并使用当前时间戳作为分值，将标识符添加到 有序集合里面。接着进程会检查自己的标识符在有序集合中的排名。如果排名低于可获取的信号 量总数(成员的排名从0开始计算)，那么表示进程成功地取得了信号量。反之，则表示进程未 能取得信号量，它必须从有序集合里面移除自己的标识符。为了处理过期的信号量，程序在将标 识符添加到有序集合之前，会先清理有序集合中所有时间戳大于超时数值(timeout number value ) 的标识符。

  ```python
  def acquire_semaphore(conn, semname, limit, timeout=10): 
    identifier = str(uuid.uuid4()) 
    now = time.time()
    pipeline = conn.pipeline(True)
    pipeline.zremrangebyscore(semname, '-inf', now - timeout)
    pipeline.zadd(semname, identifier, now) 
    pipeline.zrank(semname, identifier) 
    if pipeline.execute()[-1] < limit:	
      return identifier	
    conn.zrem(semname, identifier) 
    return None
  ```

  acquire_semaphore ()函数所做的就和前面介绍的一样:生成标识符，清除所有过期的 信号量，将新的标识符添加到有序集合里面，检查新添加的标识符在有序集合中的排名。没有什 么让人出乎意料的地方。

* 信号量释放操作非常简单:程序只需要从有序集合里面移除指定的标 识符就可以了。

  ````python
  def release semaphore(conn, semname, identifier):
  	return conn.zrem(semname, identifier)
  ````

* 这个基本的信号量实现非常好用，它不仅简单，而且运行速度也飞快。但这个信号量实现也 存在一些问题:它在获取信号量的时候，会假设每个进程访问到的系统时间都是相同的，而这一 假设在多主机环境下可能并不成立。举个例子，对于系统A和B来说，如果A的系统时间要比 B的系统时间快10毫秒，那么当A取得了最后一个信号量的时候，B只需要在10毫秒内尝试获 取信号量，就可以在A不知情的情况下，“偷走” A已经取得的信号量。对于一部分应用程序来 说这并不是一个大问题，但对于另外一部分应用程序来说却并不是如此。
* 每当锁或者信号量因为系统时钟的细微不同而导致锁的获取结果出现剧烈变化时，这个锁 或者信号量就是不公平的(unfair)。不公平的锁和信号量可能会导致客户端永远也无法取得它原 本应该得到的锁或信号量。

##### 公平信号量

* 当各个系统的系统时间并不完全相同的时候，前面介绍的基本信号量就会出现问题:系统时 钟较慢的系统上运行的客户端，将能够偷走系统时钟较快的系统上运行的客户端已经取得的信号 量，导致信号量变得不公平。我们需要减少不正确的系统时间对信号量获取操作带来的影响，使 得只要各个系统的系统时间相差不超过1秒，就不会引起信号量被偷或者信号量提早过期。

* 为了尽可能地减少系统时间不一致带来的问题，我们需要给信号量实现添加一个计数器以及 一个有序集合。其中，计数器通过持续地执行自增操作，创建出一种类似于计时器(timer)的机 制，确保最先对计数器执行自增操作的客户端能够获得信号量。另外，为了满足“最先对计数器执 行自增操作的客户端能够获得信号量”这一要求，程序会将计数器生成的值用作分值，存储到一个 “信号量拥有者”有序集合里面，然后通过检查客户端生成的标识符在有序集合中的排名来判断客户 端是否取得了信号量。

* 公平信号量和之前介绍的基本信号量一样，都是通过从系统时间有序集合里面移除过期元素 的方式来清理过期信号量的。另外，公平信号量实现还会通过ZINTERSTORE命令以及该命令的 WEIGHTS参数，将信号量的超时时间传递给新的信号量拥有者有序集合。

  ```python
  def acquire_fair_semaphore(conn, semname, limit, timeout=10): 
    identifier = str(uuid.uuid4())
    czset = semname + 'owner'
    ctr = semname + 'counter',
    now = time.time()
    pipeline = conn.pipeline(True)
    pipeline.zremrangebyscore(semname, '-inf', now - timeout)
    pipeline.zinterstore(czset, {czset: 1, semname: 0})
    pipeline.incr(ctr)
    counter = pipeline.execute()[-1]
    pipeline.zadd(semname, identifier, now)
    pipeline.zadd(czset, identifier, counter)
    pipeline.zrank(czset, identifier) 
    if pipeline.execute()[-1] < limit: 
    	return identifier 
    pipeline.zrem(semname, identifier)
    pipeline.zrem(czset, identifier)
    pipeline.execute()
    return None
  ```

  程序首先通过从超时有序集合里面 移除过期元素的方式来移除超时的信号量，接着对超时有序集合和信号量拥有者有序集合执行交 集计算，并将计算结果保存到信号量拥有者有序集合里面，覆盖有序集合中原有的数据。之后， 程序会对计数器执行自增操作，并将计数器生成的值添加到信号量拥有者有序集合里面；与此同 时，程序还会将当前的系统时间添加到超时有序集合里面。在完成以上操作之后，程序会检查当 前客户端添加的标识符在信号量拥有者有序集合中的排名是否足够低，如果是的话就表示客户端 成功取得了信号量。相反地，如果客户端未能取得信号量，那么程序将从信号量拥有者有序集合 以及超时有序集合里面移除与该客户端相关的元素。

  acquire_fair_semaphore ()函数和之前的 acquire_semaphore ()函数有一些不同 的地方。它首先清除已经超时的信号量，接着更新信号量拥有者有序集合并获取计数器生成的新 ID值，之后，函数会将客户端的当前时间戳添加到过期时间有序集合里面，并将计数器生成的 ID值添加到信号量拥有者有序集合里面，这样就可以检查标识符在有序集合里面的排名是否足 够低了。

* 在32位平台上实现公平信号量 

  * 对于运行在32位平台上的Redis来说，整数计数器的最大值将被 限制为2^31-1,也就是标准有符号整数的最大值。在大量使用信号量的情况下，32位计数器的值大 约每过2小时就会溢出一次。尽管有几种变通的方法可以避开这个问题，但对于需要生成计数器ID 的应用程序来说，最简单的办法还是直接切换到64位平台。

* 公平信号量的释放操作几乎和基础信号量的释放操作一样简单，它们之间的唯一区别在于:公平信号量的释放操作需要同时从信号量拥有者有序集合以及超时有序集合里面删除当前客户端的标识符。

  ```python
  def release_fair_semaphore(conn, semname, identifier):
  	pipeline = conn.pipeline(True) 
    pipeline.zrem(semname, identifier)
  	pipeline.zrem(semname + ':owner', identifier) 
    return pipeline.execute()[0]
  ```

  因为信号量获取操作的其中一个步骤，就是对信号量拥有者有序集合进行更新，移除那些不 再存在于超时有序集合中的标识符，所以，如果我们想要稍微偷懒一下的话，也可以在释放信号 量的时候，只移除超时有序集合里面的客户端标识符，而不对信号量拥有者有序集合执行相同的 操作。但是只从超时有序集合里面移除标识符可能会引发这样一个问题:当一个客户端执行 acquire_fair_semaphore ()函数，对信号量拥有者有序集合进行了更新，并正准备将自己 的标识符添加到超时有序集合和信号量拥有者有序集合之际，如果有另一个客户端执行信号量释 放函数，并将该客户端自己的标识符从超时有序集合中移除的话，这将导致原本能够成功执行的 信号量获取操作变为执行失败。虽然这个问题出现的几率很低，但它还是有可能会出现，因此， 为了确保程序在不同情况下都能产生正确的行为，信号量释放函数仍然会同时从两个有序集合里 面移除客户端标识符。

* 尽管这个信号量实现并不要求所有主机都拥有相同的系统时间，但各个主机在系统时间上的差距仍然需要控制在一两秒之内，从而避免信号量过早释放或者太晚释放。

##### 刷新信号量

* 对信号量进行刷新，防止其过期。

* 因为公平信号量区分开了超时有序集合和信号量拥有者有序集合，所以程序只需要对超时有序集合进行更新，就可以立即刷新信号量的超时时间了。

  ```python
  def refresh_fair_semaphore(conn, semname, identifier): 
    if conn.zadd(semname, identifier, time.time()):
      release_fair_semaphore(conn, semname, identifier) 
      return False
    return True
  ```

  只要客户端持有的信号量没有因为过期而被删除，refresh_fair_semaphore ()函数就 可以对信号量的超时时间进行刷新。另一方面，如果客户端持有的信号量已经因为超时而被删除， 那么函数将释放信号量，并将信号量已经丢失的信息告知调用者。在长时间使用信号量的时候， 我们必须以足够频繁的频率对信号量进行刷新，防止它因为过期而丢失。

* 既然我们已经可以获取、释放和刷新公平信号量了，那么是时候来解决竞争条件的问题了。

##### 消除竞争条件

* 正如在构建锁实现时所见的那样，竞争条件可能会导致操作重试或者数据出错，而解决竞争条件并不容易。不巧的是，前面介绍的信号量实现也带有可能会导致操作不正确的竞争条件。

* 比如说，当两个进程A和B都在尝试获取剩余的一个信号量时，即使A首先对计数器执行了自增操作，但只要B能够抢先将自己的标识符添加到有序集合里，并检查标识符在有序集合中的排名，那么B就可以成功地取得信号量。之后当A也将自己的标识符添加到有序集合里，并检查标识符在有序集合中的排名时，A将“偷走” B已经取得的信号量，而B只有在尝试释放信号量或者尝试刷新信号量的时候才会察觉这一点。

* 将系统时钟用作获取锁的手段提高了这类竞争条件岀现的可能性，导致信号量持有者的数量 比预期的还要多，多岀的信号量数量与各个系统时钟之间的差异有关。差异越大，出现额外信 号量持有者的可能性也就越大。虽然引入计数器和信号量拥有者有序集合可以移除系统时钟这一不确定因素，并降低竞争条件出现的几率，但由于执行信号量获取操作需要客户端和服务器进行多次通信，所以竞争条件还是有可能会发生。

* 为了消除信号量实现中所有可能出现的竞争条件，构建一个正确的计数器信号量实现，我们需要用到前面构建的带有超时功能的分布式锁。总的来说，当程序想要获取信号 量的时候，它会先尝试获取一个带有短暂超时时间的锁。如果程序成功取得了锁，那么它就会接着执行正常的信号量获取操作。如果程序未能取得锁，那么信号量获取操作也宣告失败。

  ```python
  def acquire_semaphore_with_lock(conn, semname, limit, timeout=10): 
    identifier = acquire_lock(conn, semname, acquire_timeout=.01) 
    if identifier:
      try:
        return acquire_fair_semaphore(conn, semname, limit, timeout) 
      finally:
        release_lock(conn, semname, identifier)
  ```

* 读者可能会感到有些意外，因为令我们困扰至今的竞争条件竟然只需要使用一个锁就可以轻而易举地解决掉，但这种事在使用Redis的时候并不少见:相同或者相似的问题通常会有几种不同的解决方法，而每种解决方法都有各自的优点和缺点。以下是之前介绍过的各个信号量实现的优缺点。
  * 如果你对于使用系统时钟没有意见，也不需要对信号量进行刷新，并且能够接受信号量的数量偶尔超过限制，那么可以使用我们给出的第一个信号量实现。
  * 如果你只信任差距在一两秒之间的系统时钟，但仍然能够接受信号量的数量偶尔超过限制，那么可以使用第二个信号量实现。
  * 如果你希望信号量一直都具有正确的行为，那么可以使用带锁的信号量实现来保证正确性。
* 在使用锁来解决竞争条件之后，我们拥有了几个不同的信号量实现，而它们 遵守信号量限制的程度也各不相同。 一般来说，使用最新也最严格遵守限制的实现是最好的，这不仅因为最新的实现是唯一真正正确的实现，更关键的是，如果我们因为图一时之快而使用了带有错误的简陋实现，最终可能会因为使用了太多资源而导致得不偿失。
* 这一节介绍了如何使用信号量来限制同时可运行的API调用数量:除此之外，信号量通常还用于限制针对数据库的并发请求数量，从而降低执行单个查询所需的时间。另外，当需要使用多个客户端来下载同一个服务器上的多个网页，而服务器的robots.txt却声明该服务器最多只允许同时下载(比如说)3个页面时，也可以使用信号量来防止客户端给服务器带来太大负担。

#### 任务队列

* 在处理Web客户端发送的命令请求时，某些操作的执行时间可能会比我们预期的更长一些。 通过将待执行任务的相关信息放入队列里面，并在之后对队列进行处理，用户可以推迟执行那些 需要一段时间才能完成的操作，这种将工作交给任务处理器来执行的做法被称为任务队列(task queue )o现在有很多专门的任务队列软件(如ActiveMQ、RabbitMQ、Gearman、Amazon SQS, 等等)，另外在缺少专门的任务队列可用的情况下，也有一些临时性的方法可以创建任务队列。 比方说使用定期作业来扫描一个数据表，查找那些在给定时间/日期之前或者之后被修改过/被检 査过的用户账号，并根据扫描的结果执行某些操作，这也是在创建任务队列。
* 这一节接下来将介绍两种不同类型的任务队列，第一种队列会根据任务被插入队列的顺序来尽快地执行任务，而第二种队列则具有安排任务在未来某个特定时间执行的能力。

##### 先进先出队列

* 在队列领域中，除了任务队列之外，其他几种不同的队列也常常会被人谈起——比如先进先 出(FIFO)队列、后进先出(LIFO)队列和优先级(priority)队列。因为先进先出队列具有语 义清晰、易于实现和速度快等优点，所以本节首先介绍先进先出队列，然后再说明如何实现一个 简陋的优先级队列，以及如何实现一个基于时间来执行任务的延迟队列。

* 下面再来回顾一下Fake Game公司的例子。为了鼓励不常上线的玩家进入游戏，Fake Game 公司决定增加一个选项，让玩家可以通过电子邮件来订阅商品交易市场中已售出商品和已过期商 品的相关信息。因为对外发送电子邮件可能会有非常高的延迟，甚至可能会出现发送失败的情况， 所以我们不能用平时常见的代码流(code flow)方式来执行这个邮件发送操作。为此，我们将使 用任务队列来记录邮件的收信人以及发送邮件的原因，并构建一个可以在邮件发送服务器运行变 得缓慢的时候,以并行方式一次发送多封邮件的工作进程(worker process )。

* 我们要编写的队列将以“先到先服务 ( first-come, first-served )的方式发送邮件，并且无论发送是否成功，程序都会把发送结果记录到日志里面。Redis 的列表结构允许用户通过RPUSH和LPUSH以及RPOP和LPOP,从列表的两端推入和弹出元素这次的邮件队列将使用RPUSH命令来将待发送的邮件推入列表的右端，并且因为工作进程除了发送邮件之外不需要执行其他工作，所以它将使用阻塞版本的弹出命令BLPOP从队列中弹出待 发送的邮件，而命令的最大阻塞时限为30秒(从右边推入元素并从左边弹出元素的做法，符合我 们从左向右进行阅读的习惯)。

* 我们的邮件队列由一个Redis列表构成，它包含多个JSON编码对象

* 为了将待发送邮件推入队列里面，程序会获取 发送邮件所需的全部信息，并将这些信息序列化为 JSON对象，最后使用RPUSH命令将JSON对象推 入邮件队列里面。正如前面章节所说，我们使用 JSON来进行序列化的原因在于这种格式能够被人类读懂，并且大多数编程语言都提供了能够快速编码和解码JSON格式的函数库。

  ```python
  def send_sold_email_via_queue(conn, seller, item,price, buyer):
    data = {
      'seller_id': seller,
      'item_id': item,
      'price': price,
      'buyer_id': buyer,
      'time': time.time()
    }
    conn.rpush(1 queue:emai1', json.dumps(data))
  ```

  send_sold_email_via_queue ()函数要做的就是将一封待发送邮件推入一个由列表结 构表示的队列里面，弄懂这一点应该不难。

* 从队列里面获取待发送邮件也非常容易实现。代码清单6-19展示了这一操作的实现代码:程序首先使用BLPOP命令从邮件队列里面弹出一个JSON对象，接着通过解码JSON对象来取得待发送邮件的相关信息，最后根据这些信息来发送邮件。

  ```python
  def process_sold_email_queue(conn): 
    while not QUIT:
      packed = conn.blpop(['queue:email'], 30)
      if not packed: 
        continue
      to_send = json.loads(packed[1]) 
      try:
        fetch_data_and_send_so1d_emai1(to_send) 
      except EmailSendError as err:
        log_error("Failed to send sold email", err, )
      else :
        log_success("Sent sold email"# to_send)
  ```

  process_sold_email_queue ()函数的运作原理也非常简单直接，它要做的就是从队列 里面取出待发送的邮件，并把邮件真正地发送出去。到目前为止，我们已经完成了一个用于执行邮件发送工作的任务队列，现在要考虑的问题是，如果要执行的任务不止一种，我们该怎么办？

###### 多个可执行任务

* 因为BLPOP命令每次只会从队列里面弹出一封待发送邮件，所以待发送邮件不会出现重复， 也不会被重复发送。并且因为队列只会存放待发送邮件，所以工作进程要处理的任务是非常单一 的。在一些情况下，为每种任务单独使用一个队列的做法并不少见，但是在另外一些情况下，如果一个队列能够处理多种不同类型的任务，那么事情就会方便很多。

  ```python
  def worker_watch_queue(conn, queue, callbacks): 
  while not QUIT:
    packed = conn.blpop([queue], 30)
    if not packed: 
      continue
    name, args = json.loads(packed[1]) 
    if name not in callbacks:
      log_error("Unknown callback %s"%name) 
      continue
    callbacks[name](*args)
  ```

  进程会监视用户提供的多个队列，并从多个已知的已注册回调函数里面，选出一个函数来处理 JSON 编码的函数调用。队列中每个待执行任务的格式都为 [FUNCT10N_NAME，, [ARG1, ARG2, ...]]

   有了这个通用的工作进程，我们就可以把邮件发送程序写成回调函数，并将它和其他回调函 数一同传给工作进程使用。

###### 任务优先级

* 在使用队列的时候，程序可能会需要让特定的操作优先于其他操作执行。比如对于Fake Game公司来说，他们可能会希望优先发送已售出商品邮件，其次才是已过期商品邮件。或者他 们可能会希望优先发送密码重置邮件，其次才是即将推出的线上活动的相关邮件。

* 假设现在我们需要为任务设置高、中、低3种优先级别，其中:高优先级任务在出现之后会 第一时间被执行，而中等优先级任务则会在没有任何高优先级任务存在的情况下被执行，而低优 先级任务则会在既没有任何高优先级任务，又没有任何中等优先级任务的情况下被执行。实际上 我们只需要修改代码worker_watch_queue()函数的其中两行代码，就可以给任务队列加上优先级特性

  ```python
  def worker_watch_queues(conn, queues, callbacks): 
    while not QUIT:
      packed = conn.blpop(queues, 30) 
      if not packed:
        continue
      name, args = json.loads(packed[1]) 
      if name not in callbacks:
        log_error("Unknown callback %s"%name) 
        continue
      callbacks[name](*args)
  ```

  同时使用多个队列可以降低实现优先级特性的难度。除此之外，多队列有时候也会被用于分隔不同的任务(如一个队列存放公告邮件，而另一个队列则存放提醒邮件，诸如此类)，在这种情况下，处理不同队列时可能会出现不公平的现象，为此，我们可以偶尔重新排列各个队列的顺序，使得针对队列的处理操作变得更公平一些——当某个队列的增长速度比其他队列的增长速度快的时候，这种重排操作尤为必要。

##### 延迟任务

* 使用列表结构可以实现只能执行一种任务的队列，也可以实现通过调用不同回调函数来执行不同任务的队列，甚至还可以实现简单的优先级队列，但是有些时候，这些特性还不足以满足我们的需求。举个例子，假设Fake Game公司决定给游戏添加“延迟销售”特性，让玩家可以在未来的某个时候才开始销售自己的商品，而不是立即就开始进行销售。为了实现这个延迟销售特性， 我们需要替换并修改现有的队列实现。

* 有几种不同的方法可以为队列中的任务添加延迟性质，以下是其中3种最直截了当的方法。

  * 在任务信息中包含任务的执行时间，如果工作进程发现任务的执行时间尚未来临，那么它将在短暂等待之后，把任务重新推入队列里面。
  * 工作进程使用一个本地的等待列表来记录所有需要在未来执行的任务，并在每次进行 while 循环的时候，检查等待列表并执行那些已经到期的任务。
  * 把所有需要在未来执行的任务都添加到有序集合里面，并将任务的执行时间设置为分值， 另外再使用一个进程来查找有序集合里面是否存在可以立即被执行的任务，如果有的话， 就从有序集合里面移除那个任务，并将它添加到适当的任务队列里面。

* 因为无论是进行短暂的等待，还是将任务重新推入队列里面，都会浪费工作进程的时间，所 以我们不会采用第一种方法。此外，因为工作进程可能会因为崩溃而丢失本地记录的所有待执行任务，所以我们也不会采用第二种方法。最后，因为使用有序集合的第三种方法最简单和直接， 所以我们将采取这一方法，并使用锁来保证任务从有序集合移动到任务队列时的安全性。

* 有序集合队列(ZSET queue )存储的每个被延迟的任务都是一个包含4个值的JSON列表， 这4个值分别是:唯一标识符、处理任务的队列的名字、处理任务的回调函数的名字、传给回调函数的参数。和前面的章节需要生成随机ID时的做法一样，延迟任务包含的每个唯一标识符是一个随机生成的128位UUID,这个唯一标识符可以用于区分每个被执行的任务，并在将来有需要的时候用来构建任务执行状态报告特性。在有序集合里面，任务的分值会被设置为任务的执行时间，而立即可执行的任务将被直接插入任务队列里面。

  ```python
  def execute_later(conn, queue, name, args, delay=0): 
    identifier = str(uuid.uuid4())
    item = json.dumps([identifier, queue, name, args]) 
    if delay > 0:
      conn.zadd('delayed:', item, time.time() + delay)
    else :
      conn.rpush(1 queue:' + queue, item) 
    return identifier
  ```

  当任务无需被延迟而是可以立即执行的时候，execute_later ()函数会直接将任务推入任务队列里面，而需要延迟执行的任务则会被添加到延退有序集合里面。

* 因为Redis没有提供直接的方法可以阻塞有序集合直到元素的分值低于当前UNIX时间戳为止，所以我们需要自己来查找有序集合里面分值低于当前UNIX时间戳的任务。因为所有被延迟的任务都存储在同一个有序集合队列里面，所以程序只需要获取有序集合里面排名第一的元素以及该元素的分值就可以了:如果队列里面没有任何任务，或者任务的执行时间尚未来临，那么程序将在短暂等待之后重试；如果任务的执行时间已到，那么程序将根据任务包含的标识符来获取一个细粒度锁，接着从有序集合里面移除要被执行的任务，并将它添加到适当的任务队列里面。通过将可执行的任务添加到任务队列里面而不是直接执行它们，我们可以把获取可执行任务的进程数量限制在一两个之内，而不必根据工作进程的数量来决定运行多少个获取进 程，这减少了获取可执行任务所需的花销。

  ```python
  def poll_queue(conn):
    while not QUIT:
      item = conn.zrange(' delayed:', 0, 0, withscores=True)
    if not item or item[0][1] > time.time(): 
      time.sleep(.01) 
      continue
    item = item[0][0]
    identifier, queue, function, args = json.loads(item)
    locked = acquire_lock(conn, identifier) 
    if not locked:
      continue
    if conn.zrem('delayed:', item):
      conn.rpush('queue:' + queue, item)
  ```

  因为有序集合并不具备像列表那样的阻塞弹出机制，所以程序需要不断地进行循环，并尝试从队列里面获取要被执行的任务，虽然这一操作会增大网络和处理器 的负载，但因为我们只会运行一两个这样的程序，所以这并不会消耗太多资源。如果想要进一步 减少poll_queue()函数的运行开销，那么可以在函数里面添加一个自适应方法(adaptive method ),让函数在一段时间内都没有发现可执行的任务时，自动延长休眠的时间，或者根据下 一个任务的执行时间来决定休眠的时长，并将休眠时长的最大值限制为100毫秒，从而确保执行 时间距离当前时间不远的任务可以及时被执行。

###### 关于优先级

* 因为延迟任务最终都会被推入对应的任务队列里面，并以相同的优先级执行，所以延迟任务 的优先级和任务队列里面存储的普通任务的优先级是基本相同的。但是，如果我们打算在延迟任 务的执行时间到达时，优先执行这些任务的话，应该怎么办呢？
* 要做到这一点的最简单办法就是添加多个额外的队列，使得可以立即执行的延迟任务出现在 队列的最前面。举个例子，对于“高优先级”、“中等优先级”、“低优先级”这3个队列，我 们可以分别创建“被延迟的高优先级”、“被延迟的中等优先级”、“被延迟的低优先级”这3 个队列, 并将这些队列 `['high-delayed', "high”， nmedium-delayed, "medium”, low-delayed, low]` 的顺序传入 worker_watch_queues ()函数里面，这样的话，具有相同优先级的延迟队列就会先于非延迟队列被处理。
* 一些读者可能会觉得好奇，“既然要将延迟任务放置到队列的最前面，那么为什么不使用 LPUSH命令而是使用RPUSH命令呢？ ”假设所有工作进程都在处理中等优先级队列包含的任务， 并且这些任务需要花费数秒钟才能执行完毕，如果这时有3个延迟任务可以执行，那么程序将使 用LPUSH命令把它们依次推入中等优先级队列里面:首先推入第一个可执行的延迟任务，然后 是第二个，最后是第三个。但是这样一来，最后被推入中等优先级队列里面的延迟任务就会最先被执行，这违背了我们对于“最先可执行的延迟任务总是最先被执行”的预期。
* 在使用任务队列的过程中，有时候需要让任务通过某种消息系统来向应用程序的其他部分进行报告。接下来的一节将介绍消息队列的创建方法，并说明如何使用这些队列将消息发送至单个 接收者，或者在多个发送者和接收者之间进行通信。

#### 消息拉取

* 两个或多个客户端在互相发送和接收消息的时候，通常会使用以下两种方法来传递消息。第 一种方法被称为消息推送(push messaging),也就是由发送者来确保所有接收者已经成功接收到 了消息。Redis内置了用于进行消息推送的PUBLISH命令和SUBSCRIBE命令。第二种方法被称为消息拉取 ( pull messaging ),这种方法 要求接收者自己去获取存储在某种邮箱(mailbox )里面的消息。
* 尽管消息推送非常有用，但是当客户端因为某些原因而没办法一直保持在线的时候，采用这一消息传递方法的程序就会岀现各种各样的问题。为了解决这个问题，我们将编写两个不同的消息拉取方法，并使用它们来代替PUBLISH命令和SUBSCRIBE命令。
* 简单来说，PUBLISH和SUBSCRIBE的缺陷在于客户端必须一直在线才能接收到消息，断线可能会导致客户端丢失信息；除此之外，旧版Redis可能会因为订阅者处理消息的速度不够快而变得不稳定甚至崩溃，又或者被管理员杀死。
* 因为只有单个接收者的消息传递操作和前面介绍过的先进先出队列有很多共通之处，所以本 节首先会介绍如何实现只有单个接收者的消息传递操作，然后再介绍如何开发具有多个接收者的消息传递操作。通过使用自制的多接收者消息传递操作来代替Redis的PUBLISH命令和SUBSCRIBE命令，即使接收者曾经断开过连接，它也可以一封不漏地收到所有发给它的消息。

##### 单接收者消息的发送与订阅替代品

* Redis的其中一种常见用法，就是让不同种类的客户端(如服务器进程、聊天室用户等)去监听或者等待它们各自所独有的频道，并作为频道消息的唯一接收者，从频道那里接收传来的消息。很多程序员都选择了使用Redis的PUBLISH命令和SUBSCRIBE命令来发送和等待消息， 但是当我们需要在遇到连接故障的情况下仍然不丢失任何消息的时候，PUBLISH命令和 SUBSCRIBE命令就派不上用场了。
* 让我们把目光从Fake Game公司转向Fake Garage创业公司，后者正打算开发一个移动通信 应用程序，这个应用通过连接服务器来发送和接收类似短信或彩信的消息，它基本上就是一个文 字短信和图片彩信的替代品。应用程序的身份验证部分以及通信部分将由使用Redis作为后端的 Web服务器负责，除此之外，消息的存储和路由也是由Redis负责。每条消息都只会被发送至一个客户端，这一点极大地简化了我们要解决的问题。为了以这种方式来处理消息，我们将为每个移动客户端使用一个列表结构。发送者会把消息放到接收者的列 表里面，而接收者客户端则通过发送请求来获取最新的消息。通过使用HTTP 1.1协议的流水线请求特性或者新型的Web套接字功能，移动客户端既可以在一次请求里面获取所有未读消息， 又可以每次请求只获取一条未读消息，还可以通过使用LTRIM命令移除列表的前10个元素来获取最新的10条未读消息。
* 因为未读消息队列是使用列表结构来实现的，所以发送者只需要检査接收者的未读消息队列，就可以知道接收者最近是否有上线、接收者是否已经收到了之前发送的消息，以及接收者是否有太多未读消息等待处理。对于像PUBLISH命令和SUBSCRIBE命令这种要求接收者必须一直在线的系统来说，被传递的消息可能会丢失，而客户端根本不会察觉这一点。此外，在旧版Redis里面，速度缓慢的客户端可能会导致输出缓冲区不受控制地增长，而在新版Redis里面， 速度缓慢的客户端可能会被断开连接。
* 我们已经实现了只有单个接收者的消息传递操作，接下来是时候讲讲如何在给定频道有多个监听者的情况下，替换PUBLISH命令和SUBSCRIBE命令了。

##### 多接收者消息的发送与订阅替代品

* 只有单个接收者的消息传递操作虽然有用，但它还是没办法取代PUBLISH命令和SUBSCRIBE 命令在多接收者消息传递方面的作用。为此，我们可以改变一下自己看待这个问题的方式。Redis 的PUBLISH命令和SUBSCRIBE命令在很多方面就像一个群组聊天(group chat)功能，一个用户是否在线决定了他能否进行群组聊天，而我们想要做的就是去掉“用户需要一直在线才能接收到消息”这一要求，并以群组聊天为背景，实现具有多个接收者的消息传递操作。
* 每个新创建的群组都会有一些初始用户，各个用户都可以按照自己的意愿来参加或者离开群组。群组使用有序集合来记录参加群组的用户，其中有序集合的成员为用户的名字，而成员的分值则是用户在群组内接收到的最大消息ID. 用户也会使用有序集合来记录自己参加的所有群组, 其中有序集合的成员为群组ID,而成员的分值则是用户在群组内接收到的最大消息ID。

###### 创建群组聊天会话

* 群组聊天产生的内容会以消息为成员、消息ID为分值的形式存储在有序集合里面。在创建新群组的时候，程序首先会对一个全局计数器执行自增操作，以此来获得一个新的群组 ID。之后，程序会把群组的初始用户全部添加到一个有序集合里面，并将这些用户在群组里面的最大已读消息ID初始化为0, 另外还会把这个新群组的ID添加到记录用户已参加群组的有序集合里面。 最后，程序会将一条初始化消息放置到群组有序集合里面，以此来向参加聊天的用户发送初始化消息。

  ```
  def create_chat(conn, sender, recipients, message, chat_id=None):
    chat_id = chat_id or str(conn.incr('ids:chat:'))
    recipients.append(sender)
    recipientsd = diet((r, 0) for r in recipients)
    pipeline = conn.pipeline(True)
    pipeline.zadd('chat:' + chat_id, **recipientsd)
    for rec in recipientsd:
      pipeline.zadd('seen:' + rec, chat_id, 0)
    pipeline.execute()
    return send_message(conn, chat_id, sender, message)
  ```

###### 发送消息

* 为了向群组发送消息，程序需要创建一个新的消息ID,并将想要发送的消息添加到群组消息有序集合(chat's messages ZSET )里面。虽然这个消息发送操作包含了一个竞争条件，但只要使用锁就可以很容易地解决这个问题。

  ```python
  def send_message(conn, chat_id, sender, message): 
    identifier = acquire_lock(conn, 'chat:' + chat_id) 
    if not identifier:
      raise Exception("Couldn't get the lock") 
    try:
      mid = conn.incr('ids:' + chat_id)
      ts = time.time()
      packed = json.dumps((
        'id': mid,
        'ts': ts,
        'sender': sender,
        'message': message, ))
      conn.zadd('msgs:' + chat_id, packed, mid) 
    finally:
      release_lock(conn, 'chat:' + chat_id, identifier)
    return chat_id
  ```

  发送群组消息的绝大部分工作都是在筹备待发送消息的各项信息，之后只要把准备好的消息添加到有序集合里面，发送操作就完成了。send_message()函数使用锁包围了构建消息的代 码以及将消息添加到有序集合里面的代码，这样做的原因和我们之前使用锁来实现计数器信号量的原因是一样的。一般来说，当程序使用一个来自Redis的值去构建另一个将要被添加到Redis 里面的值时，就需要使用锁或者由WATCH、MULTI和EXEC组成的事务来消除竞争条件。考虑到锁的性能比事务要好，所以send_message()函数选择了使用锁而不是事务。

###### 获取消息

* 为了获取用户的所有未读消息，程序需要对记录用户数据的有序集合执行ZRANGE命令，以此来获取群组ID以及已读消息ID,然后根据这两个ID,对用户参与的所有群组的消息有序集合执行ZRANGEBYSCORE命令，以此来取得用户在各个群组内的未读消息。在取得聊天消息之后， 程序将根据消息ID对已读有序集合以及群组有序集合里面的用户记录进行更新。最后，程序会查找并清除那些已经被所有人接收到了的群组消息。

  ```python
  def fetch_pending_messages(conn, recipient):
      seen = conn.zrange('seen:' + recipient, 0, -1, withscores=True) #A
  
      pipeline = conn.pipeline(True)
  
      for chat_id, seen_id in seen:                               #B
          pipeline.zrangebyscore(                                 #B
              b'msgs:' + chat_id, seen_id+1, 'inf')                #B
      chat_info = list(zip(seen, pipeline.execute()))                   #C
  
      for i, ((chat_id, seen_id), messages) in enumerate(chat_info):
          if not messages:
              continue
          messages[:] = list(map(json.loads, messages))
          seen_id = messages[-1]['id']                            #D
          conn.zadd(b'chat:' + chat_id, {recipient: seen_id})      #D
  
          min_id = conn.zrange(                                   #E
              b'chat:' + chat_id, 0, 0, withscores=True)           #E
  
          pipeline.zadd('seen:' + recipient, {chat_id: seen_id})  #F
          if min_id:
              pipeline.zremrangebyscore(                          #G
                  b'msgs:' + chat_id, 0, min_id[0][1])             #G
          chat_info[i] = (chat_id, messages)
      pipeline.execute()
  
      return chat_info
  ```

  获取未读消息的工作就是遍历用户参与的所有群组，取出每个群组的未读消息，并顺便清理那些已经被所有群组用户看过的消息。

###### 加入群组和离开群组

* 我们已经知道了如何从群组里面获取未读消息，接下来要做的就是实现加入群组和离开群组这两个操作了。为了把用户加入给定的群组里面，程序需要将群组的ID作为成员添加到用户的已读消息有序集合里面，并将这个群组最新一条消息的ID设置为成员的分值。此外，程序还会将用户添加到群组的成员列表里面，而用户在成员列表里面的分值同样为最新群组消息的ID。

  ```python
  def join_chat(conn, chat_id, user):
      message_id = int(conn.get('ids:' + chat_id))             
      pipeline = conn.pipeline(True)
      pipeline.zadd('chat:' + chat_id, {user: message_id})
      pipeline.zadd('seen:' + user, {chat_id: message_id})
      pipeline.execute()
  ```

  join_chat()函数要做的就是在用户和群组之间以及群组和用户的已读消息有序集合之 间，建立起正确的引用信息。

* 为了将用户从给定的群组中移除，程序需要从群组有序集合里面移除用户的ID,并从用户的已读消息有序集合里面移除给定群组的相关信息。在移除操作完成之后，如果群组已经没有任何成员存在，那么群组的消息有序集合以及消息 ID 计数器将被删除。如果群组还有成员存在，那么程序将再次查找并清除那些已经被所有成员阅读过的群组消息。

  ```python
  def leave_chat(conn, chat_id, user):
      pipeline = conn.pipeline(True)
      pipeline.zrem('chat:' + chat_id, user)                      #A
      pipeline.zrem('seen:' + user, chat_id)                      #A
      pipeline.zcard('chat:' + chat_id)                           #B
  
      if not pipeline.execute()[-1]:
          pipeline.delete('msgs:' + chat_id)                      #C
          pipeline.delete('ids:' + chat_id)                       #C
          pipeline.execute()
      else:
          oldest = conn.zrange(                                   #D
              'chat:' + chat_id, 0, 0, withscores=True)           #D
          conn.zremrangebyscore('msgs:' + chat_id, 0, oldest[0][1])     #E
  ```

* 本节以群组聊天为背景，介绍了构建一个完整的多接收者消息拉取系统的具体方法，每当我们希望接收者不会因为断线而错过任何消息的时候，就可以使用本节介绍的方法来代替 PUBLISH 命令和SUBSCRIBE命令。如果有需要的话，我们也可以多花一点儿工夫，把群组聊天实现里面的有序集合结构换成列表结构，或者把发送消息时的加锁操作转移到清理旧消息时执行。我们之所以坚持使用有序集合而不是列表，是因为使用有序集合可以更方便地从每个群组里 面取出当前的消息ID。同样地，通过将加锁操作交给消息发送者来执行，消息接收者可以免于请求额外的数据，并且也无需在执行清理操作时进行加锁，这从总体上提高了性能。

#### 使用 Redls 进行文件分发

* 在构建分布式软件和分布式系统的时候，我们常常需要在多台机器上复制、分发或者处理数据文件，而现有的工具可以以几种不同的方式来完成这些工作:如果服务器需要持续地分发文件，那么常见的做法是使用NFS或者Samba来载入一个路径(path )或者驱动器；对于内容会逐渐发生变化的文件来说，常见的做法是使用一款名为Rsync的软件来尽量减少两个系统之间需要传输的数据量；在需要将多个文件副本分发到多台机器上面的时候，可以使用BitTorrent协议来将文件部分地(partial)分发到多台机器上面，然后通过让各台机器互相分享自己所拥有的数据来降低服 务器的负载。
* 遗憾的是，以上提到的所有方法都有显著的安装成本以及相对的价值。虽然NFS和Samba 都很好用，但是由于这两种技术都对操作系统进行了整合，所以它们在网络连接不完美的时候都会出现明显的问题(有时候甚至在网络连接无恙的情况下，也是如此)。Rsync旨在解决网络不稳定带来的问题，让单个文件或者多个文件可以部分地进行传送和续传(resume ),但Rsync在开始传输文件之前必须先下载整个文件，并且负责获取文件的软件也必须与Rsync进行对接， 这一点是否可行也是一个需要考虑的地方。尽管BitTorrent是一个了不起的技术，但它也只适用于服务器在发送文件方面遇到了限制或者网络未被充分使用的情况下，并且这种技术也需要软件与BitTorrent客户端进行对接，而我们需要获取文件的系统上可能并没有合适的BitTorrent 客户端可用。
* 除了上面提到的问题之外，上述3种方法还需要设置并维护账号、权限以及服务器。因为我们已经有了一个安装完毕、正在运行并且随时可用的Redis, 所以我们还是使用Redis来进行文件分发比较好，这也可以避免使用其他软件时碰到的一些问题:Redis的客户端会妥善地处理连接故障，通过客户端也可以直接获取数据，并且针对数据的处理操作可以立即执行而不必等待整个文件出现。

##### 根据地理位置聚合用户数据

* 在使用`IP所属城市查找程序`来定位用户访问游戏时所在的地点之后，Fake Game公司打算从国家、地区、城市等多个不同纬度，对用户随着时间形成的访问模式进行聚合计算，为此，Fake Game公司需要分析许多体积以GB计算的日志文件，而我们要做的就是实现 执行聚合计算所需的回调函数，并使用这些函数来实时地分析日志数据。
* Fake Game公司已经存在了大约两年时间，他们每天的用户数 量大约有10万人，而每个用户每天大约会产生10个事件，也就是总共有大约73亿行的日志需 要分析。如果我们使用的是前面提到的几种文件分发技术的其中一种，那么程序就需要先将日志 复制到进行日志分析的各台机器上面，然后才真正地开始进行日志分析。这种做法虽然可行，但 是复制日志这一操作潜在地延缓了日志分析操作的进行，并且还会占用每台机器的存储空间，因为直到日志分析完成之后，复制到机器上的日志才会被清除。
* 虽然我们可以考虑编写一个一次性的 MapReduce 过程来处理所有日志文件，以此来代替将文件复制到各个机器里面的做法，但 MapReduce 并不会在各个待处理的任务之间共享内存(每 个任务通常就是一个日志行)，而手动地进行内存共享只会浪费更多的时间。说得更具体一些， 程序如果将IP所属城市的查找表(look table )载入Python的内存里面，那么它就可以以每秒 大约20万次的速度执行IP所属城市査找操作，这比单个Redis实例执行相同查询时的速度还要 快。与此类似，如果我们使用MapReduce来处理日志的话，那么至少需要同时运行好几个Redis实 例才能跟得上MapReduce的处理速度。
  * MapReduce (又称Map/Reduce )是Google推广的一种分布式计算方式，它可以高效并且简单地解决某些问题。
* 在理解了 NFS和Samba、文件复制、MapReduce这几种常见的技术并不适合用来解决Fake Game公司目前面临的问题之后，接下来我们将看到实际执行查找操作时需要解决的几个问题。

###### 在本地进行数据聚合计算

* 为了高效地处理数量繁多的日志，程序在对Redis进行更新之前，需要先将聚合数据缓存到 本地，以此来减少程序执行所需的通信往返次数。这样做的原因在于:如果程序每天需要处理大 约1000万个日志行的话，那么它就需要对Redis进行大约1000万次的写入，而如果程序在本地 对每个国家在一天之内产生的日志进行聚合计算的话，因为国家的数量只有大约300个，所以它 只需要向Redis写入大约300个值就可以了。这显著地降低了程序与Redis之间的通信往返次数, 减少了需要执行的命令数量，并最终缩短了处理日志所需的时间。

* 如果我们不釆取任何本地缓存措施，那么进行10次聚合计算就需要花费大约10天时间来处 理所有数据。幸运的是，所有在一天之内产生的国家维度或者地区维度的日志，都可以在完成聚 合计算之后再发送给Rediso因为我们的数据取样集合中只有大约350 000个城市，其中10%的 城市覆盖了超过90%的玩家，所以我们同样可以在本地缓存所有城市维度的聚合数据。只要把聚 合数据缓存到本地，聚合计算的吞吐量就不会被Redis所限制。

* 假设我们已经为5.3节中介绍过的由有序集合和散列组成的IP查找表创建了缓存副本，那么 剩下要考虑的就是如何对日志进行聚合计算了。首先，让我们来了解一下聚合计算需要处理的日 志行一它们包含IP地址、日期、时间以及被执行的操作，就像这样:`173.194.38.137 2011-10-10 13:55:36 achievement-762`

* 为了每天对不同国家的日志行进行聚合计算，程序会把以上格式的日志行作为其中一个参 数，传递给执行聚合计算的回调函数，而回调函数则负责对相应的国家计数器执行自增操作，并 在处理完所有日志行之后，将聚合计算的结果写入Redis里面。

  ```python
  aggregates = defaultdict(lambda: defaultdict(int))      #A
  def daily_country_aggregate(conn, line):
      if line:
          line = line.split()
          ip = line[0]                                    #B
          day = line[1]                                   #B
          country = find_city_by_ip_local(ip)[2]          #C
          aggregates[day][country] += 1                   #D
          return
  
      for day, aggregate in list(aggregates.items()):           #E
          conn.zadd('daily:country:' + day, aggregate)  #E
          del aggregates[day]                             #E
  ```

* 